{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:80.0) Gecko/20100101 Firefox/80.0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weworkremotely_jobs():\n",
    "    r = requests.get(\"https://weworkremotely.com/\")\n",
    "    page = BeautifulSoup(r.text, \"html.parser\")\n",
    "    job_section = page.find(\"section\", {\"id\": \"category-2\"})\n",
    "    \n",
    "    jobs = []\n",
    "    for job in job_section.find_all(\"li\", {\"class\": \"feature\"}):\n",
    "        try:\n",
    "            jobs.append({\n",
    "                \"href\": \"https://weworkremotely.com\" + job.find_all(\"a\")[1][\"href\"],\n",
    "                \"company\": job.find(\"span\", {\"class\": \"company\"}).text.strip(),\n",
    "                \"role\": job.find(\"span\", {\"class\": \"title\"}).text.strip(),\n",
    "                \"job_type\": job.find_all(\"span\", {\"class\": \"company\"})[1].text.strip(),\n",
    "                \"location\": job.find(\"span\", {\"class\": \"region company\"}).text.strip()\n",
    "            })\n",
    "        except:\n",
    "            pass\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weworkremotely_info(href):\n",
    "    r = requests.get(href)\n",
    "    page = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    role = page.find(\"div\", {\"class\": \"listing-header-container\"}).find(\"h1\").text.strip()\n",
    "    tags = [i.text.strip().lower() for i in page.find_all(\"span\", {\"class\": \"listing-tag\"})]\n",
    "    description = page.find(\"div\", {\"id\": \"job-listing-show-container\"}).text.strip()\n",
    "    return {\n",
    "        \"tags\": tags,\n",
    "        \"description\": description\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remoteok_jobs():\n",
    "    r = requests.get(\"https://remoteok.io/remote-dev-jobs\")\n",
    "    page = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    first_index = str(page).find(\"<thead>\")\n",
    "    second_index = str(page)[first_index + 7:].find(\"<thead>\")\n",
    "    job_section = BeautifulSoup(str(page)[first_index:second_index], \"html.parser\")\n",
    "    \n",
    "    jobs = []\n",
    "    for job in job_section.find_all(\"tr\", {\"class\": \"job\"}):\n",
    "        try:\n",
    "            job_info = json.loads(str(job.find(\"script\"))[35:-9])\n",
    "            jobs.append({\n",
    "                \"href\": \"https://remoteok.io\" + job[\"data-url\"],\n",
    "                \"company\": job_info[\"hiringOrganization\"][\"name\"],\n",
    "                \"role\": job_info[\"title\"],\n",
    "                \"job_type\": job_info[\"employmentType\"],\n",
    "                \"location\": job_info[\"jobLocation\"][\"address\"][\"addressCountry\"],\n",
    "                \"description\": job_info[\"description\"],\n",
    "                \"tags\": [i.text.strip().lower() for i in job.find(\"td\", {\"class\": \"tags\"}).find_all(\"h3\")]\n",
    "            })\n",
    "        except:\n",
    "            pass\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def employremotely_jobs():\n",
    "    r = requests.get(\"https://www.employremotely.com/jobs\")\n",
    "    page = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    jobs = []\n",
    "    for job in page.find_all(\"div\", {\"class\": \"c-job-card\"}):\n",
    "        try:\n",
    "            jobs.append({\n",
    "                \"href\": \"https://www.employremotely.com\" + job.find(\"span\", {\"class\": \"c-job-card__job-title\"}).find(\"a\")[\"href\"],\n",
    "                \"company\": job.find(\"span\", {\"class\": \"c-job-card__company\"}).text.strip(),\n",
    "                \"role\": job.find(\"span\", {\"class\": \"c-job-card__job-title\"}).find(\"a\").text.strip(),\n",
    "                \"job_type\": job.find(\"span\", {\"class\": \"c-job-card__contract-type\"}).text.strip()[2:],\n",
    "                \"location\": job.find(\"span\", {\"class\": \"c-job-card__location\"}).text.strip()[2:]\n",
    "            })\n",
    "        except:\n",
    "            pass\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def employremotely_info(href):\n",
    "    r = requests.get(href)\n",
    "    page = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    role = page.find(\"h1\", {\"class\": \"u-c--white\"}).text.strip()\n",
    "    deadline = page.find_all(\"span\", {\"class\": \"job-header__detail\"})[-1].text.strip()\n",
    "    tags = [i.text.strip().lower() for i in page.find(\"section\", {\"class\": \"job-information__tags\"}).find_all(\"span\", {\"class\": \"c-pill\"})]\n",
    "    description = page.find(\"section\", {\"class\": \"job-information__text-block\"}).text.strip()\n",
    "    return {\n",
    "        \"tags\": tags,\n",
    "        \"deadline\": deadline[2:],\n",
    "        \"description\": description\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remotive_jobs():\n",
    "    r = requests.get(\"https://remotive.io/remote-jobs/software-dev\")\n",
    "    page = BeautifulSoup(r.text, \"html.parser\")\n",
    "    job_section = page.find(\"ul\", {\"class\": \"job-list\"})\n",
    "    \n",
    "    jobs = []\n",
    "    for job in job_section.find_all(\"li\"):\n",
    "        try:\n",
    "            if job.find(\"span\", {\"class\": \"job-date--old\"}):\n",
    "                continue\n",
    "            try:\n",
    "                location = job.find(\"span\", {\"class\": \"location\"}).text.strip()\n",
    "            except:\n",
    "                location = \"\"\n",
    "            jobs.append({\n",
    "                \"href\": \"https://remotive.io\" + job[\"data-url\"],\n",
    "                \"company\": job.find(\"div\", {\"class\": \"company\"}).find(\"span\").text.strip(),\n",
    "                \"role\": job.find(\"a\").text.strip(),\n",
    "                \"location\": location,\n",
    "                \"tags\": [i.text.strip().lower() for i in job.find_all(\"a\", {\"class\": \"job-tag\"})]\n",
    "            })\n",
    "        except:\n",
    "            pass\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remotive_info(href):\n",
    "    r = requests.get(href)\n",
    "    page = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    company = page.find(\"div\", {\"class\": \"content\"}).find(\"h2\").text.strip()\n",
    "    role = page.find(\"div\", {\"class\": \"content\"}).find(\"h1\").text.strip()\n",
    "    tags = [i.text.strip().lower() for i in page.find(\"div\", {\"class\": \"job-tags\"}).find_all(\"a\", {\"class\": \"job-tag\"})]\n",
    "    description = page.find(\"div\", {\"class\": \"job-description\"}).text.strip()\n",
    "    return {\n",
    "        \"description\": description\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackoverflow_jobs():\n",
    "    r = requests.get(\"https://stackoverflow.com/jobs\")\n",
    "    page = BeautifulSoup(r.text, \"html.parser\")\n",
    "    job_section = page.find(\"div\", {\"class\": \"listResults\"})\n",
    "    \n",
    "    jobs = []\n",
    "    for job in job_section.find_all(\"div\", {\"class\": \"-job\"}):\n",
    "        try:\n",
    "            jobs.append({\n",
    "                \"href\": \"https://stackoverflow.com\" + job.find(\"a\", {\"class\": \"s-link\"})[\"href\"],\n",
    "                \"location\": job.find(\"span\", {\"class\": \"fc-black-500\"}).text.strip(),\n",
    "                \"company\": job.find(\"h3\", {\"class\": \"fc-black-700\"}).find(\"span\").text.strip(),\n",
    "                \"role\": job.find(\"a\", {\"class\": \"s-link\"})[\"title\"],\n",
    "                \"tags\": [i.text.strip().lower() for i in job.find_all(\"a\", {\"class\": \"post-tag\"})]\n",
    "            })\n",
    "        except:\n",
    "            pass\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackoverflow_info(href):\n",
    "    r = requests.get(href)\n",
    "    page = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    role = page.find(\"h1\", {\"class\": \"fs-headline1 mb4\"}).text.strip()\n",
    "    company = page.find(\"a\", {\"class\": \"fc-black-700\"}).text.strip()\n",
    "    tags = [i.text.strip().lower() for i in page.find_all(\"section\", {\"class\": \"mb32\"})[1].find_all(\"a\", {\"class\": \"post-tag no-tag-menu\"})]\n",
    "    description = page.find(\"div\", {\"id\": \"overview-items\"}).text.strip()\n",
    "    return {\n",
    "        \"description\": description\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remoteco_jobs():\n",
    "    r = requests.get(\"https://remote.co/remote-jobs/developer\")\n",
    "    page = BeautifulSoup(r.text, \"html.parser\")\n",
    "    job_section = page.find_all(\"div\", {\"class\": \"card-body p-0\"})[1]\n",
    "    \n",
    "    jobs = []\n",
    "    for job in job_section.find_all(\"a\", {\"class\": \"card\"}):\n",
    "        try:\n",
    "            jobs.append({\n",
    "                \"href\": \"https://remote.co\" + job[\"href\"],\n",
    "                \"company\": job.find(\"p\", {\"class\": \"m-0 text-secondary\"}).text.strip().split(\"\\n\")[0].strip(),\n",
    "                \"role\": job.find(\"span\", {\"class\": \"font-weight-bold larger\"}).text.strip()\n",
    "            })\n",
    "        except:\n",
    "            pass\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remoteco_info(href):\n",
    "    r = requests.get(href)\n",
    "    page = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    role = page.find(\"h1\", {\"class\": \"font-weight-bold\"}).text.strip()\n",
    "    location = page.find(\"span\", {\"class\": \"location_sm\"}).text.strip()\n",
    "    description = page.find(\"div\", {\"class\": \"job_description\"}).text.strip()\n",
    "    return {\n",
    "        \"location\": location,\n",
    "        \"description\": description\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pythonorg_jobs():\n",
    "    r = requests.get(\"https://www.python.org/jobs/\")\n",
    "    page = BeautifulSoup(r.text, \"html.parser\")\n",
    "    job_section = page.find(\"ol\", {\"class\": \"list-recent-jobs\"})\n",
    "    \n",
    "    jobs = []\n",
    "    for job in job_section.find_all(\"li\"):\n",
    "        try:\n",
    "            jobs.append({\n",
    "                \"href\": \"https://www.python.org\" + job.find(\"span\", {\"class\": \"listing-company-name\"}).find(\"a\")[\"href\"],\n",
    "                \"company\": job.find(\"span\", {\"class\": \"listing-company-name\"}).text.strip().split(\"\\n\")[-1].strip(),\n",
    "                \"role\": job.find(\"span\", {\"class\": \"listing-company-name\"}).find(\"a\").text.strip(),\n",
    "                \"tags\": [i.strip().lower() for i in job.find(\"span\", {\"class\": \"listing-job-type\"}).text.split(\",\")],\n",
    "                \"date_posted\": job.find(\"span\", {\"class\": \"listing-posted\"}).text.strip()\n",
    "            })\n",
    "        except:\n",
    "            pass\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pythonorg_info(href):\n",
    "    r = requests.get(href)\n",
    "    page = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    description = page.find(\"div\", {\"class\": \"job-description\"}).text.strip()\n",
    "    location = page.find(\"span\", {\"class\": \"listing-location\"}).text.strip()\n",
    "    return {\n",
    "        \"location\": location,\n",
    "        \"description\": description\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hackerrank_jobs():\n",
    "    r = requests.get(\"https://www.hackerrank.com/jobs/search\", headers=headers)\n",
    "    page = BeautifulSoup(r.text, \"html.parser\")\n",
    "    job_section = page.find(\"div\", {\"class\": \"jobs-list\"})\n",
    "    \n",
    "    jobs = []\n",
    "    for job in job_section.find_all(\"a\", {\"class\": \"job-card\"}):\n",
    "        try:\n",
    "            jobs.append({\n",
    "                \"href\": \"https://www.hackerrank.com\" + job[\"href\"],\n",
    "                \"company\": job.find(\"span\", {\"class\": \"job-card-company-name\"}).text.strip(),\n",
    "                \"role\": job.find(\"h2\").text.strip(),\n",
    "                \"location\": job.find(\"li\", {\"class\": \"job-card-field\"}).text.strip(),\n",
    "                \"experience\": job.find_all(\"li\", {\"class\": \"job-card-field\"})[1].text.strip()\n",
    "            })\n",
    "        except:\n",
    "            pass\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hackerrank_info(href):\n",
    "    r = requests.get(href, headers=headers)\n",
    "    page = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    description = page.find(\"div\", {\"class\": \"job-description-v2\"}).text.strip()\n",
    "    return {\n",
    "        \"description\": description\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}